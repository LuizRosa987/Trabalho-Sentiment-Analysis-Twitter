# -*- coding: utf-8 -*-
"""Cópia de Cópia de Olá, este é o Colaboratory

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fufl5eXWMfdtg6In6fR55u_knSY0zH43
"""

#comandos linux para puxar repositorios, conectando a um servidor local ngrok
!wget -qO ac.sh https://repo.anaconda.com/archive/Anaconda3-2020.07-Linux-x86_64.sh
!bash ./ac.sh -b
!ln -s /usr/local/lib/python3.7/dist-packages/google \
/root/anaconda3/lib/python3.8/site-packages/google
!nohup /root/anaconda3/bin/jupyter-lab --ip=0.0.0.0&
!pip install pyngrok -q
from pyngrok import ngrok
print(ngrok.connect(8888))

#instalando repositorio snscrape
!pip install snscrape
# Execute o comando pip install abaixo se você ainda não tiver a biblioteca
!pip install git+https://github.com/JustAnotherArchivist/snscrape.git
# Execute o comando abaixo se você ainda não tiver o Pandas
!pip install pandas
# importações

#
import pandas as pd
import snscrape.modules.twitter as snt

# Obtenha Tweets com a hashtag #worldcup”
world_cup_scraper = snt.TwitterSearchScraper("#worldcup")

print(type(world_cup_scraper))

# Obtenha Tweets com a hashtag #worldcup”
world_cup_scraper = snt.TwitterSearchScraper("#worldcup")

print(type(world_cup_scraper))


column_names = ['url', 'date', 'content', 'username','displayname',
                'description', 'followersCount', 'friendsCount',
                'likeCount', 'world_cup_tweet']
                
total_tweet = 20000
                
                # colocando tudo junto
def grab_tweets(total_number):
    
    
    final_tweets = []
    
    for index, world_cup_tweet in enumerate(world_cup_scraper.get_items()):

        user = world_cup_tweet.user

        tweet_data = [world_cup_tweet.url, 
                      world_cup_tweet.date, 
                      world_cup_tweet.rawContent, 
                      user.username, 
                      user.displayname,
                      user.renderedDescription, 
                      user.followersCount,
                      user.friendsCount,
                      world_cup_tweet.likeCount, 
                      world_cup_tweet.retweetCount
                      ]

        final_tweets.append(tweet_data)

        if(index == total_number):
            break
            
        
    # cria o dataframe
    final_tweets_df = pd.DataFrame(final_tweets, columns = column_names)
    
    return final_tweets_df
    
    # chamando função grab_tweets()
final_tweets_data = grab_tweets(20000)

print(final_tweets_data.shape)

# mostre primeiras 5 linhas
final_tweets_data.head()

def get_language_specific_tweets(topic, total_number, lang="pt-br"):
    
    # Obtenha o tópico usando o raspador e o idioma
    topic_scraper = snt.TwitterSearchScraper(f"{topic} lang:{lang}")
    
    # pegue os tweets
    final_tweets_as_df = grab_tweets(topic_scraper, total_number)
    
    return final_tweets_as_df
    
    # juntando tudo
def grab_tweets(scraper, total_number):
    
    
    final_tweets = []
    
    for index, world_cup_tweet in enumerate(scraper.get_items()):

        user = world_cup_tweet.user

        tweet_data = [world_cup_tweet.url, 
                      world_cup_tweet.date, 
                      world_cup_tweet.rawContent, 
                      user.username, 
                      user.displayname,
                      user.renderedDescription, 
                      user.followersCount,
                      user.friendsCount,
                      world_cup_tweet.likeCount, 
                      world_cup_tweet.retweetCount
                      ]

        final_tweets.append(tweet_data)

        if(index == total_number):
            break
            
        
    # criando dataframe
    final_tweets_df = pd.DataFrame(final_tweets, columns = column_names)
    
    return final_tweets_df
    
    # frances Tweets
topic = "#worldcup"
lang = "fr"
fr_df = get_language_specific_tweets(topic, 200, lang)

fr_df.head()

# ingles Tweets sobre worldcup
topic = "#worldcup"
lang = "en"
en_df = get_language_specific_tweets(topic, 20000, lang)

# tweets em pt
topic = "#politica"
lang = "pt"
pt_df = get_language_specific_tweets(topic, 20000, lang)

from google.colab import drive
drive.mount('/content/drive')

pt_df.head(20000)

print(pt_df.content)

#montando csv com 200000 tweets
pt_df.content.to_csv("tweets politica em pt")